{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "- learn how to use early stopping to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv(\"../../data/diabetes.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and testing set\n",
    "X, y = df.iloc[:, :-1].values, df.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, shuffle=True, random_state=89\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.55541\tvalidation_1-logloss:0.61137\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 20 rounds.\n",
      "[1]\tvalidation_0-logloss:0.46299\tvalidation_1-logloss:0.55319\n",
      "[2]\tvalidation_0-logloss:0.40203\tvalidation_1-logloss:0.52379\n",
      "[3]\tvalidation_0-logloss:0.35649\tvalidation_1-logloss:0.50181\n",
      "[4]\tvalidation_0-logloss:0.32238\tvalidation_1-logloss:0.49589\n",
      "[5]\tvalidation_0-logloss:0.30001\tvalidation_1-logloss:0.48972\n",
      "[6]\tvalidation_0-logloss:0.27803\tvalidation_1-logloss:0.48230\n",
      "[7]\tvalidation_0-logloss:0.25759\tvalidation_1-logloss:0.48017\n",
      "[8]\tvalidation_0-logloss:0.24287\tvalidation_1-logloss:0.48426\n",
      "[9]\tvalidation_0-logloss:0.23216\tvalidation_1-logloss:0.48511\n",
      "[10]\tvalidation_0-logloss:0.21984\tvalidation_1-logloss:0.49243\n",
      "[11]\tvalidation_0-logloss:0.21085\tvalidation_1-logloss:0.49724\n",
      "[12]\tvalidation_0-logloss:0.20525\tvalidation_1-logloss:0.49429\n",
      "[13]\tvalidation_0-logloss:0.19574\tvalidation_1-logloss:0.49894\n",
      "[14]\tvalidation_0-logloss:0.18415\tvalidation_1-logloss:0.50417\n",
      "[15]\tvalidation_0-logloss:0.17592\tvalidation_1-logloss:0.51045\n",
      "[16]\tvalidation_0-logloss:0.16835\tvalidation_1-logloss:0.51565\n",
      "[17]\tvalidation_0-logloss:0.16008\tvalidation_1-logloss:0.52189\n",
      "[18]\tvalidation_0-logloss:0.15265\tvalidation_1-logloss:0.52818\n",
      "[19]\tvalidation_0-logloss:0.14962\tvalidation_1-logloss:0.52839\n",
      "[20]\tvalidation_0-logloss:0.14169\tvalidation_1-logloss:0.53530\n",
      "[21]\tvalidation_0-logloss:0.13546\tvalidation_1-logloss:0.53755\n",
      "[22]\tvalidation_0-logloss:0.12908\tvalidation_1-logloss:0.53306\n",
      "[23]\tvalidation_0-logloss:0.12671\tvalidation_1-logloss:0.53752\n",
      "[24]\tvalidation_0-logloss:0.12391\tvalidation_1-logloss:0.53711\n",
      "[25]\tvalidation_0-logloss:0.12056\tvalidation_1-logloss:0.54248\n",
      "[26]\tvalidation_0-logloss:0.11403\tvalidation_1-logloss:0.54600\n",
      "[27]\tvalidation_0-logloss:0.10732\tvalidation_1-logloss:0.55239\n",
      "Stopping. Best iteration:\n",
      "[7]\tvalidation_0-logloss:0.25759\tvalidation_1-logloss:0.48017\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "clf = XGBClassifier()\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "clf.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=eval_set, \n",
    "    eval_metric=\"logloss\", \n",
    "    early_stopping_rounds=20, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The test accuracy of XGBoost is: 75.76%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance of the model\n",
    "preds_test = clf.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, preds_test)\n",
    "print(\"[INFO] The test accuracy of XGBoost is: %.2f%%\" % (acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
